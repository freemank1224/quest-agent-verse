# AIæ•™å­¦ç³»ç»Ÿæ¨¡å‹ç®¡ç†æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹é…ç½®ç®¡ç†ç³»ç»Ÿï¼Œå®ç°å¯¹AIæ•™å­¦ç³»ç»Ÿä¸­æ‰€æœ‰Agentæ¨¡å‹çš„çµæ´»ç®¡ç†ã€‚

### æ ¸å¿ƒç‰¹æ€§

- **ğŸ”§ é…ç½®åŒ–ç®¡ç†** - é€šè¿‡YAMLé…ç½®æ–‡ä»¶ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ¨¡å‹
- **ğŸ¢ åˆ†Teamç®¡ç†** - æ”¯æŒæ•™å­¦å›¢é˜Ÿã€å­¦ä¹ å›¢é˜Ÿã€ç›‘æ§å›¢é˜Ÿç‹¬ç«‹é…ç½®
- **ğŸ”„ åŠ¨æ€åˆ‡æ¢** - è¿è¡Œæ—¶æ— éœ€é‡å¯å³å¯åˆ‡æ¢æ¨¡å‹
- **ğŸ›¡ï¸ å¤‡ç”¨æœºåˆ¶** - è‡ªåŠ¨æ•…éšœè½¬ç§»åˆ°å¤‡ç”¨æ¨¡å‹
- **âš¡ é¢„è®¾é…ç½®** - ä¸€é”®åº”ç”¨é«˜æ€§èƒ½ã€ç»æµæ¨¡å¼ç­‰é¢„è®¾
- **ğŸŒ ç¯å¢ƒç®¡ç†** - å¼€å‘/æµ‹è¯•/ç”Ÿäº§ç¯å¢ƒç‹¬ç«‹é…ç½®

## ğŸ“ æ–‡ä»¶ç»“æ„

```
backend/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ models.yaml              # æ¨¡å‹é…ç½®æ–‡ä»¶
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ model_manager.py     # æ¨¡å‹ç®¡ç†å™¨
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ teaching_team/
â”‚   â”‚       â””â”€â”€ modern_teacher_agent.py  # ç°ä»£åŒ–Agent
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ model_management.py  # ç®¡ç†API
â””â”€â”€ test_model_management.py     # æµ‹è¯•è„šæœ¬
```

## ğŸ”§ é…ç½®æ–‡ä»¶è¯¦è§£

### åŸºç¡€é…ç½®ç»“æ„

```yaml
# config/models.yaml

# å…¨å±€é»˜è®¤é…ç½®
global_defaults:
  default_provider: "ollama"
  default_model_code: "qwen3_32b"
  timeout: 30
  max_retries: 3

# æ¨¡å‹æä¾›å•†é…ç½®
model_providers:
  # OpenAIé…ç½®
  openai:
    gpt4_turbo:
      provider: "openai"
      model_id: "gpt-4-turbo"
      description: "GPT-4 Turbo - é«˜æ€§èƒ½é€šç”¨æ¨¡å‹"
      config:
        api_key: "${OPENAI_API_KEY}"
        temperature: 0.7
        max_tokens: 4096
        timeout: 30

  # xAIé…ç½®
  xai:
    grok_beta:
      provider: "xai"
      model_id: "grok-beta"
      description: "Grok Beta - xAIçš„ä¸»åŠ›æ¨¡å‹"
      config:
        api_key: "${XAI_API_KEY}"
        base_url: "https://api.x.ai/v1"
        temperature: 0.7
        max_tokens: 4096

  # Google Geminié…ç½®
  gemini:
    gemini_pro:
      provider: "gemini"
      model_id: "gemini-pro"
      description: "Gemini Pro - Googleçš„é«˜æ€§èƒ½æ¨¡å‹"
      config:
        api_key: "${GOOGLE_API_KEY}"
        temperature: 0.7
        max_tokens: 4096

  # Ollamaæœ¬åœ°æ¨¡å‹é…ç½®
  ollama:
    qwen3_32b:
      provider: "ollama"
      model_id: "qwen3:32b"
      description: "Qwen3 32B - é«˜æ€§èƒ½ä¸­æ–‡æ¨¡å‹"
      config:
        host: "http://localhost:11434"
        timeout: 60
        keep_alive: "5m"

# Agentå›¢é˜Ÿé…ç½®
agent_teams:
  teaching_team:
    teacher_agent:
      model_code: "qwen3_32b"
      fallback_models: ["gpt4_turbo", "gemini_pro"]
      specific_config:
        temperature: 0.7
        max_tokens: 2048
        enable_reasoning: true
        enable_memory: true

# å¿«é€Ÿåˆ‡æ¢é¢„è®¾
presets:
  high_performance:
    teaching_team:
      teacher_agent: "gpt4_turbo"
      course_planner: "gpt4_turbo"
  
  cost_effective:
    teaching_team:
      teacher_agent: "qwen3_32b"
      course_planner: "qwen3_32b"
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå˜é‡é…ç½®

```bash
# è®¾ç½®APIå¯†é’¥
export OPENAI_API_KEY="your_openai_api_key"
export XAI_API_KEY="your_xai_api_key"
export GOOGLE_API_KEY="your_google_api_key"

# è®¾ç½®è¿è¡Œç¯å¢ƒ
export ENVIRONMENT="development"  # development, testing, production
```

### 2. åŸºç¡€ä½¿ç”¨

```python
from utils.model_manager import get_agent_model

# è·å–æ•™å¸ˆAgentçš„æ¨¡å‹ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
teacher_model = get_agent_model("teaching_team", "teacher_agent")

# ä½¿ç”¨é«˜æ€§èƒ½é¢„è®¾
teacher_model = get_agent_model("teaching_team", "teacher_agent", "high_performance")
```

### 3. åˆ›å»ºç°ä»£åŒ–Agent

```python
from agents.teaching_team.modern_teacher_agent import ModernTeacherAgent

# åˆ›å»ºä½¿ç”¨é»˜è®¤é…ç½®çš„æ•™å¸ˆAgent
teacher = ModernTeacherAgent()

# åˆ›å»ºä½¿ç”¨é«˜æ€§èƒ½é¢„è®¾çš„æ•™å¸ˆAgent
teacher = ModernTeacherAgent(preset="high_performance")

# åˆ›å»ºä½¿ç”¨ç»æµæ¨¡å¼çš„æ•™å¸ˆAgent
teacher = ModernTeacherAgent(preset="cost_effective")
```

## ğŸ”„ æ¨¡å‹åˆ‡æ¢æ“ä½œ

### 1. é€šè¿‡ä»£ç åˆ‡æ¢

```python
from utils.model_manager import get_model_manager

manager = get_model_manager()

# åˆ‡æ¢å•ä¸ªAgentçš„æ¨¡å‹
manager.update_agent_model("teaching_team", "teacher_agent", "gpt4_turbo")

# åº”ç”¨é¢„è®¾é…ç½®åˆ°æ‰€æœ‰Agent
manager.apply_preset("high_performance")

# è·å–å½“å‰æ¨¡å‹ä¿¡æ¯
model_info = manager.get_agent_current_model("teaching_team", "teacher_agent")
print(f"å½“å‰æ¨¡å‹: {model_info['model_code']}")
```

### 2. é€šè¿‡é…ç½®æ–‡ä»¶åˆ‡æ¢

ç›´æ¥ä¿®æ”¹ `config/models.yaml` æ–‡ä»¶ï¼š

```yaml
agent_teams:
  teaching_team:
    teacher_agent:
      model_code: "gpt4_turbo"  # æ”¹ä¸ºä½¿ç”¨GPT-4
      fallback_models: ["gemini_pro", "qwen3_32b"]
```

ç„¶åé‡æ–°åŠ è½½é…ç½®ï¼š

```python
manager.reload_config()
```

### 3. é€šè¿‡APIåˆ‡æ¢

```bash
# åˆ‡æ¢å•ä¸ªAgentæ¨¡å‹
curl -X POST "http://localhost:8000/api/models/agent/switch" \
  -H "Content-Type: application/json" \
  -d '{
    "team_name": "teaching_team",
    "agent_name": "teacher_agent", 
    "model_code": "gpt4_turbo"
  }'

# åº”ç”¨é¢„è®¾é…ç½®
curl -X POST "http://localhost:8000/api/models/preset/apply" \
  -H "Content-Type: application/json" \
  -d '{"preset_name": "high_performance"}'
```

## ğŸ“Š ç®¡ç†APIæ¥å£

### è·å–æ¨¡å‹çŠ¶æ€

```bash
# è·å–æ‰€æœ‰æ¨¡å‹çŠ¶æ€
GET /api/models/status

# è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
GET /api/models/available

# è·å–ç‰¹å®šAgentçš„æ¨¡å‹ä¿¡æ¯
GET /api/models/agent/{team_name}/{agent_name}

# å¥åº·æ£€æŸ¥
GET /api/models/health
```

### æ¨¡å‹ç®¡ç†æ“ä½œ

```bash
# åˆ‡æ¢Agentæ¨¡å‹
POST /api/models/agent/switch
{
  "team_name": "teaching_team",
  "agent_name": "teacher_agent",
  "model_code": "gpt4_turbo"
}

# åº”ç”¨é¢„è®¾é…ç½®
POST /api/models/preset/apply
{
  "preset_name": "high_performance"
}

# é‡æ–°åŠ è½½é…ç½®
POST /api/models/reload

# æ¸…é™¤æ¨¡å‹ç¼“å­˜
DELETE /api/models/cache
```

## ğŸ›ï¸ é¢„è®¾é…ç½®

ç³»ç»Ÿæä¾›ä¸‰ç§é¢„è®¾é…ç½®ï¼š

### 1. é«˜æ€§èƒ½é¢„è®¾ (high_performance)
- ä½¿ç”¨æœ€å…ˆè¿›çš„æ¨¡å‹ï¼ˆGPT-4, Gemini 1.5 Proç­‰ï¼‰
- é€‚åˆç”Ÿäº§ç¯å¢ƒå’Œé‡è¦ä»»åŠ¡
- æˆæœ¬è¾ƒé«˜ä½†æ•ˆæœæœ€ä½³

### 2. ç»æµæ¨¡å¼ (cost_effective)
- å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬
- æ··åˆä½¿ç”¨äº‘æœåŠ¡å’Œæœ¬åœ°æ¨¡å‹
- é€‚åˆæ—¥å¸¸å¼€å‘å’Œæµ‹è¯•

### 3. æœ¬åœ°ä¼˜å…ˆ (local_first)
- ä¼˜å…ˆä½¿ç”¨æœ¬åœ°Ollamaæ¨¡å‹
- æˆæœ¬æœ€ä½ï¼Œéšç§æ€§æœ€å¥½
- é€‚åˆå¼€å‘ç¯å¢ƒå’Œç¦»çº¿åœºæ™¯

## ğŸ”§ é«˜çº§é…ç½®

### 1. æ·»åŠ æ–°çš„æ¨¡å‹æä¾›å•†

```yaml
model_providers:
  # æ·»åŠ æ–°çš„æä¾›å•†
  anthropic:
    claude_3:
      provider: "anthropic"
      model_id: "claude-3-opus-20240229"
      description: "Claude 3 Opus - Anthropicçš„æ——èˆ°æ¨¡å‹"
      config:
        api_key: "${ANTHROPIC_API_KEY}"
        temperature: 0.7
        max_tokens: 4096
```

### 2. è‡ªå®šä¹‰Agenté…ç½®

```yaml
agent_teams:
  teaching_team:
    teacher_agent:
      model_code: "claude_3"
      fallback_models: ["gpt4_turbo", "gemini_pro"]
      specific_config:
        temperature: 0.8        # æ›´é«˜çš„åˆ›é€ æ€§
        max_tokens: 3072        # è‡ªå®šä¹‰tokené™åˆ¶
        enable_reasoning: true   # å¯ç”¨æ¨ç†å·¥å…·
        custom_prompt: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIæ•™å¸ˆ..."
```

### 3. ç¯å¢ƒç‰¹å®šé…ç½®

```yaml
environments:
  development:
    default_provider: "ollama"
    log_level: "DEBUG"
    enable_fallback: true
    
  production:
    default_provider: "openai"
    log_level: "WARNING"
    enable_fallback: true
    rate_limit:
      requests_per_minute: 100
      burst_limit: 10
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
cd backend
python test_model_management.py
```

æµ‹è¯•å†…å®¹åŒ…æ‹¬ï¼š
- é…ç½®æ–‡ä»¶éªŒè¯
- æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–
- æ¨¡å‹å®ä¾‹åˆ›å»º
- åŠ¨æ€åˆ‡æ¢åŠŸèƒ½
- é¢„è®¾é…ç½®åº”ç”¨
- APIæ¥å£æµ‹è¯•

### æ‰‹åŠ¨éªŒè¯

```python
# éªŒè¯æ¨¡å‹åˆ‡æ¢
from utils.model_manager import get_model_manager

manager = get_model_manager()

# æŸ¥çœ‹å½“å‰é…ç½®
status = manager.get_model_status()
print(f"ç¯å¢ƒ: {status['environment']}")
print(f"å¯ç”¨æä¾›å•†: {status['available_providers']}")

# æµ‹è¯•æ¨¡å‹åˆ‡æ¢
original_model = manager.get_agent_current_model("teaching_team", "teacher_agent")
print(f"åŸå§‹æ¨¡å‹: {original_model['model_code']}")

# åˆ‡æ¢åˆ°æ–°æ¨¡å‹
success = manager.update_agent_model("teaching_team", "teacher_agent", "gpt4_turbo")
if success:
    new_model = manager.get_agent_current_model("teaching_team", "teacher_agent")
    print(f"æ–°æ¨¡å‹: {new_model['model_code']}")
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥**
   ```
   é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: config/models.yaml
   è§£å†³: ç¡®ä¿é…ç½®æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼Œæˆ–ä½¿ç”¨ç»å¯¹è·¯å¾„
   ```

2. **APIå¯†é’¥æœªè®¾ç½®**
   ```
   é”™è¯¯: åˆ›å»º openai æ¨¡å‹å®ä¾‹å¤±è´¥
   è§£å†³: è®¾ç½®ç¯å¢ƒå˜é‡ export OPENAI_API_KEY="your_key"
   ```

3. **Ollamaè¿æ¥å¤±è´¥**
   ```
   é”™è¯¯: æ— æ³•è¿æ¥åˆ° http://localhost:11434
   è§£å†³: å¯åŠ¨OllamaæœåŠ¡ ollama serve
   ```

4. **æ¨¡å‹ä»£å·ä¸å­˜åœ¨**
   ```
   é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹é…ç½®: unknown_model
   è§£å†³: æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹ä»£å·æ˜¯å¦æ­£ç¡®
   ```

### è°ƒè¯•æŠ€å·§

1. **å¯ç”¨è¯¦ç»†æ—¥å¿—**
   ```python
   import logging
   logging.basicConfig(level=logging.DEBUG)
   ```

2. **æ£€æŸ¥æ¨¡å‹çŠ¶æ€**
   ```python
   manager = get_model_manager()
   status = manager.get_model_status()
   print(json.dumps(status, indent=2, ensure_ascii=False))
   ```

3. **æ¸…é™¤ç¼“å­˜é‡è¯•**
   ```python
   manager.clear_cache()
   manager.reload_config()
   ```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. æ¨¡å‹ç¼“å­˜
- ç³»ç»Ÿè‡ªåŠ¨ç¼“å­˜å·²åˆ›å»ºçš„æ¨¡å‹å®ä¾‹
- é¿å…é‡å¤åˆå§‹åŒ–æé«˜æ€§èƒ½
- å¯æ‰‹åŠ¨æ¸…é™¤ç¼“å­˜å¼ºåˆ¶é‡æ–°åˆ›å»º

### 2. å¤‡ç”¨æ¨¡å‹ç­–ç•¥
- é…ç½®å¤šä¸ªå¤‡ç”¨æ¨¡å‹ç¡®ä¿å¯ç”¨æ€§
- æŒ‰ä¼˜å…ˆçº§è‡ªåŠ¨æ•…éšœè½¬ç§»
- è®°å½•å¤±è´¥åŸå› ä¾¿äºè°ƒè¯•

### 3. ç¯å¢ƒä¼˜åŒ–
- å¼€å‘ç¯å¢ƒä½¿ç”¨æœ¬åœ°æ¨¡å‹é™ä½å»¶è¿Ÿ
- ç”Ÿäº§ç¯å¢ƒä½¿ç”¨äº‘æœåŠ¡ä¿è¯ç¨³å®šæ€§
- æµ‹è¯•ç¯å¢ƒç¦ç”¨å¤‡ç”¨æ¨¡å‹å¿«é€Ÿå¤±è´¥

## ğŸ”® æœªæ¥æ‰©å±•

### è®¡åˆ’åŠŸèƒ½

1. **æ¨¡å‹æ€§èƒ½ç›‘æ§**
   - å“åº”æ—¶é—´ç»Ÿè®¡
   - æˆåŠŸç‡ç›‘æ§
   - æˆæœ¬è¿½è¸ª

2. **æ™ºèƒ½æ¨¡å‹é€‰æ‹©**
   - åŸºäºä»»åŠ¡ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹
   - è´Ÿè½½å‡è¡¡å’ŒåŠ¨æ€è°ƒåº¦
   - A/Bæµ‹è¯•æ”¯æŒ

3. **é…ç½®çƒ­æ›´æ–°**
   - æ— éœ€é‡å¯çš„é…ç½®æ›´æ–°
   - é…ç½®ç‰ˆæœ¬ç®¡ç†
   - å›æ»šæœºåˆ¶

4. **Webç®¡ç†ç•Œé¢**
   - å¯è§†åŒ–é…ç½®ç®¡ç†
   - å®æ—¶çŠ¶æ€ç›‘æ§
   - æ“ä½œæ—¥å¿—è®°å½•

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·ï¼š

1. æŸ¥çœ‹æœ¬æŒ‡å—çš„æ•…éšœæ’é™¤éƒ¨åˆ†
2. è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯é…ç½®
3. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
4. æäº¤Issueæè¿°å…·ä½“é—®é¢˜

---

**æ³¨æ„**: è¯·ç¡®ä¿åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¦¥å–„ä¿ç®¡APIå¯†é’¥ï¼Œå»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡ã€‚ 